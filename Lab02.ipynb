{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"figures/svtLogo.png\"/>\n",
    "</div>\n",
    "<center><h1>Mathematical Optimization for Engineers</h1></center>\n",
    "<center><h2>Lab 2</h2></center>\n",
    "<center><h2>Basic math</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\newcommand{\\mr}[1]{\\mathrm{#1}}\n",
    "\\newcommand{\\D}{\\displaystyle}\n",
    "\\newcommand{\\bm}[1]{\\text{\\mathbf $#1$}}\n",
    "\\newcommand{\\bx}{\\mathbf{ x}}\n",
    "\\newcommand{\\f}{\\mathbf{{f}}}\n",
    "\\newcommand{\\g}{\\mathbf{ g}}\n",
    "\\newcommand{\\h}{\\mathbf{ h}}\n",
    "\\newcommand{\\R}{\\mathbb R}\n",
    "\\newcommand{\\A}{\\mathbf{ A}}\n",
    "\\newcommand{\\br}{\\boldsymbol{r}}\n",
    "\\newcommand{\\bp}{\\boldsymbol{p}}\n",
    "\\newcommand{\\bnabla}{\\mathbf{\\nabla}}\n",
    "$$\n",
    "In this lab, we will learn about Jacobians, gradients and Hessian matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Notation</u>: Please note that throughout the course, we will denote matrices and vectors with boldface letters. Their components will be denoted by normal letters with subscripts. For example,\n",
    "$$\n",
    "\\bx = \\left(\\begin{array}{c}\n",
    "x_1 \\\\ \n",
    "\\vdots \\\\ \n",
    "x_n\n",
    "\\end{array} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jacobian\n",
    "Let $\\ \\mathbf \\f:\\R^n \\rightarrow \\R^m,\\,\\bx \\mapsto \\f(\\bx)$ be a continuously differentiable function, where\n",
    "$$\n",
    "\\bx = \\left(\\begin{array}{c}\n",
    "x_1 \\\\ \n",
    "\\vdots \\\\ \n",
    "x_n\n",
    "\\end{array} \\right) , \\qquad \\f(\\bx)  = \\left(\\begin{array}{c}\n",
    "f_1(\\bx) \\\\ \n",
    "\\vdots \\\\ \n",
    "f_m(\\bx) \n",
    "\\end{array} \\right).\n",
    "$$\n",
    "The Jacobian $\\f'(\\bx)$ is defined by the matrix\n",
    "$$\n",
    "\\f'(\\bx) = \\left(  \\begin{array}{ccc}\n",
    "\\frac{\\partial f_1(\\bx)}{\\partial x_1} & \\cdots & \\frac{\\partial f_1(\\bx)}{\\partial x_n} \\\\ \n",
    "\\vdots & \\ddots & \\vdots \\\\ \n",
    "\\frac{\\partial f_m(\\bx)}{\\partial x_1} & \\cdots & \\frac{\\partial f_m(\\bx)}{\\partial x_n}\n",
    "\\end{array}  \\right).\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient\n",
    "\n",
    "Now, let $f:\\R^n \\rightarrow \\R,\\,\\bx \\mapsto f(\\bx)$ be a *scalar-valued* continuously differentiable function\n",
    "with vector-valued arguments.\n",
    "The gradient $\\bnabla f(\\bx)$ and Jacobian $f'(\\bx)$ are defined as the column vector and row vector, respectively,\n",
    "\n",
    "$$\n",
    "\\bnabla f(\\bx)  = \\left(\\begin{array}{c}\n",
    "\t\\frac{\\partial f(\\bx)}{\\partial x_1} \\\\ \n",
    "\t\\vdots \\\\ \n",
    "\t\\frac{\\partial f(\\bx)}{\\partial x_n}\n",
    "\\end{array} \\right), \\qquad  f'(\\bx)  = \\left(\\begin{array}{ccc}  \n",
    "\\frac{\\partial f(\\bx)}{\\partial x_1} & \n",
    "\\cdots & \n",
    "\\frac{\\partial f(\\bx)}{\\partial x_n}\n",
    "\\end{array}\\right).\n",
    "$$\n",
    "\n",
    "Note that  $\\bnabla f(\\bx)^T=f'(\\bx)$.<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient of the scalar product of two functions\n",
    "\n",
    "Let $\\g,\\h:\\R^n\\rightarrow\\R^n$ be two continuously differentiable functions. We want to compute the\n",
    "gradient of $f:\\R^n\\rightarrow \\R,\\;\\bx \\mapsto f(\\bx) = \\g(\\bx)^T\\h(\\bx)$, where $\\bx\\in\\R^n$.\n",
    "We have\n",
    "\n",
    "$$\n",
    "f(\\bx) = \\g(\\bx)^T\\h(\\bx) = \\sum_{i=1}^{n} g_i(\\bx)h_i(\\bx).\n",
    "$$\n",
    "\n",
    "The derivative with respect to $x_j$ ($1 \\le j \\le n$) is computed by the application of the product rule\n",
    "\n",
    "\\begin{equation}\\label{eq:1}\n",
    "\\frac{\\partial f(\\bx)}{\\partial x_j} = \\sum_{i=1}^{n} \\left(\\frac{\\partial g_i(\\bx)}{\\partial x_j}h_i(\\bx)  +g_i(\\bx)\\frac{\\partial h_i(\\bx)}{\\partial x_j}\\right).\n",
    "\\end{equation}\n",
    "\n",
    "With the notations\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\g(\\bx)}{\\partial x_j}   = \\left(\\begin{array}{c}\n",
    "\\frac{\\partial g_1(\\bx)}{\\partial x_j} \\\\ \n",
    "\\vdots \\\\ \n",
    "\\frac{\\partial g_n(\\bx)}{\\partial x_j}\n",
    "\\end{array} \\right) \\quad \\text{and} \\quad \n",
    "\\frac{\\partial \\h(\\bx)}{\\partial x_j}   \n",
    "= \\left(\\begin{array}{c}\n",
    "\\frac{\\partial h_1(\\bx)}{\\partial x_j} \\\\ \n",
    "\\vdots \\\\ \n",
    "\\frac{\\partial h_n(\\bx)}{\\partial x_j}\n",
    "\\end{array} \\right), \\text{ respectively},\n",
    "$$\n",
    "\n",
    "we can rewrite the equation as\n",
    "\n",
    "$$\n",
    "\\frac{\\partial f(\\bx)}{\\partial x_j} = \\frac{\\partial \\g(\\bx)}{\\partial x_j} ^T \\h(\\bx) + \n",
    "\\g(\\bx)^T \\frac{\\partial \\h(\\bx)}{\\partial x_j}  = \\h(\\bx)^T\\frac{\\partial \\g(\\bx)}{\\partial x_j}\n",
    "+\\g(\\bx)^T \\frac{\\partial \\h(\\bx)}{\\partial x_j}\n",
    "$$\n",
    "\n",
    "Finally,\n",
    "\n",
    "$$\n",
    "\\bnabla f(\\bx)^T = f'(\\bx) = \\h(\\bx)^T \\g'(\\bx) + \\g(\\bx)^T\\h'(\\bx).\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\implies \\bnabla f(\\bx) = \\bnabla g(\\bx) \\ \\h(\\bx) + \\bnabla h(\\bx) \\ \\g(\\bx).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derivative of quadratic form\n",
    "If $\\A\\in\\R^{n\\times n}$ is a symmetric matrix, the function\n",
    "\n",
    "$$\n",
    "f:\\R^n\\rightarrow \\R,\\quad\\bx\\mapsto f(\\bx) = \\bx^T\\,\\A\\,\\bx\n",
    "$$ is called a quadratic form. <br>\n",
    "<br>\n",
    "With the definitions,\n",
    "\n",
    "$$\n",
    "\\g(\\bx) := \\bx \\ \\text{and } \\ \\h(\\bx):= \\A\\,\\bx,\n",
    "$$\n",
    "\n",
    "we have $f(\\bx) = \\g(\\bx)^T\\h(\\bx)$, i.e., exactly the situation as above.\n",
    "With $\\g'(\\bx) = \\mathbf{ I}$, where $\\mathbf{ I}$ denotes the unity matrix, and $\\h'(\\bx) = \\A$, it is more or less easy to see that the gradient of $f$ is given by\n",
    "\n",
    "$$\n",
    "\\bnabla f(\\bx) = 2\\,\\A\\,\\bx.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1\n",
    "Let the function $f:\\R^2 \\rightarrow \\R$ be defined as\n",
    "$ f(x,y) = \\frac{1}{2} (x^2 + \\alpha y^2), \\alpha \\in \\R $\n",
    "\n",
    "Find all stationary points of the function $f$.\n",
    "<details> \n",
    "We compute the gradient and set it equal to zero:\n",
    "$\n",
    "\\begin{equation*}\n",
    "\\frac{\\partial f}{\\partial x} = x, \\; \\; \\frac{\\partial f}{\\partial y} =\n",
    "\\alpha y.\n",
    "\\end{equation*}\n",
    "$\n",
    "   \n",
    "If $\\alpha \\neq 0$ then the stationary point is $x^{*}=(0,0)$.\t\n",
    "If $\\alpha = 0$ then any $y$ satisfies $\\frac{\\partial f}{\\partial y} =\n",
    "0$. Hence we have a \"line\" of stationary points: $(0,u), \\; u \\in\n",
    "\\mathbb{R}$.\n",
    "</details>\n",
    "\n",
    "Calculate the Hessian of the function $f$ for arbitrary $x$ and $y$.\n",
    "<details>\n",
    "We have a smooth function (at least twice continuous and differentiable). Thus, we compute:\n",
    "$\\begin{equation*}\n",
    "\t\\frac{\\partial^2 f}{\\partial x^2} = 1, \\; \\; \\frac{\\partial^2 f}{\\partial\n",
    "\t\ty^2} = \\alpha, \\;\\;  \\frac{\\partial^2 f}{\\partial x \\partial y} = 0.\n",
    "\\end{equation*} $\n",
    "    \n",
    "to obtain the Hessian:\n",
    "$\\begin{equation}\n",
    "\tH := \\begin{pmatrix}\n",
    "\t1  & 0 \\\\\n",
    "\t0 & \\alpha\n",
    "\t\\end{pmatrix}.\n",
    "\t\\end{equation}$\n",
    "</details>\n",
    "\n",
    "What are the eigenvalues of the Hessian of the function $f$ with respect to $x$ and $y$?\n",
    "<details>\n",
    "  Since the Hessian is a diagonal matrix one can easily retrieve\n",
    "\tits eigenvalues as the elements on the diagonal: $\\{1, \\alpha\\}$.\n",
    "</details>\n",
    "\n",
    "Characterize the stationary points for positive and negative $\\alpha$.\n",
    "<details>\n",
    "If $\\alpha > 0$ then $H$ is positive definite, hence by means of the second order sufficient conditions we conclude that\n",
    "\t$(0,0)$ is a minimum point.\n",
    "\t\n",
    "If $\\alpha < 0$ then $H$ is indefinite, rendering us the saddle\n",
    "\tpoint $(0,0)$.\n",
    "</details>\n",
    "\n",
    "Characterize the convexity of the function for every $\\alpha$.\n",
    "<details>\n",
    "The convexity can be determined by means of the definiteness of the Hessian $H$:\n",
    "    \n",
    "a. for $\\alpha > 0$ $H$ is positive definite $\\Rightarrow$ $f$ is strictly convex;\n",
    "    \n",
    "b. for $\\alpha =0$ $H$ is positive semidefinite\t$\\Rightarrow$ $f$ is convex (but not strictly);\n",
    "    \n",
    "c. for $\\alpha <0$ $H$ is indefinite \n",
    "\t\t$\\Rightarrow$ $f$ is neither convex nor concave.    \n",
    "</details>\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T13:16:30.966165Z",
     "start_time": "2025-05-15T13:16:30.958899Z"
    }
   },
   "source": [
    "def rosenbrock(x):\n",
    "    return ((x[0]-1)**2 + 100*(x[1]-x[0]**2)**2)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T13:56:31.421055Z",
     "start_time": "2025-05-15T13:56:31.414742Z"
    }
   },
   "source": [
    "# compute hessian using autograd\n",
    "import autograd\n",
    "import numpy as np\n",
    "x0 = np.array([1., 1.])   # stationary point\n",
    "hessian_rosenbrock = autograd.hessian(rosenbrock)(x0)\n",
    "print(f\"Hessian of the function f:\\n\"\n",
    "      f\"--------------------------\\n\"\n",
    "      f\"{hessian_rosenbrock}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hessian of the function f:\n",
      "--------------------------\n",
      "[[ 802. -400.]\n",
      " [-400.  200.]]\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T13:56:09.270998Z",
     "start_time": "2025-05-15T13:56:09.265710Z"
    }
   },
   "source": [
    "# compute the eigenvalues using numpy\n",
    "import numpy as np\n",
    "eigenvalues = np.linalg.eig(hessian_rosenbrock)\n",
    "print(f\"Eigenvalues of the function f:\\n\"\n",
    "      f\"------------------------------\"\n",
    "      f\"\\n{eigenvalues}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues of the function f:\n",
      "------------------------------\n",
      "EigResult(eigenvalues=array([1.00160064e+03, 3.99360767e-01]), eigenvectors=array([[ 0.89478425,  0.44649877],\n",
      "       [-0.44649877,  0.89478425]]))\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
